{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " AI-Powered Customer Sentiment Analysis Using Self-Attention, Transformers, Natural language processing"
      ],
      "metadata": {
        "id": "_oU3Ul68-8ns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Œ PROBLEM STATEMENT\n",
        "\n",
        "Given a restaurant review in textual form, build a Transformer-based NLP model that can automatically predict whether the sentiment of the review is Positive or Negative.\n",
        "\n",
        "The model should learn semantic relationships between words using multi-head self-attention, without relying on recurrent networks such as RNN or LSTM."
      ],
      "metadata": {
        "id": "ci2J4eMdktud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŽ¯ PROJECT OBJECTIVES\n",
        "\n",
        "Understand how raw text is processed in NLP\n",
        "\n",
        "Learn how Transformers work internally\n",
        "\n",
        "Apply self-attention for sentiment classification\n",
        "\n",
        "Build an end-to-end NLP pipeline\n",
        "\n",
        "Perform real-time sentiment prediction"
      ],
      "metadata": {
        "id": "mswVirzCkwjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP 1: Upload dataset (Google Colab)\n",
        "# ============================================\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "ZltBbnrTZQ6q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "d39405d1-cf5f-45f9-e030-e50124fa9206"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3be6ff58-80bc-4162-9d87-ee7eeaabff8a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3be6ff58-80bc-4162-9d87-ee7eeaabff8a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving yelp_labelled.txt to yelp_labelled (1).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# IMPORT LIBRARIES\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "import nltk # Tokenization, Stopwords , Stemming / Lemmatization\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Added to resolve LookupError for punkt_tab\n",
        "\n",
        "# Downloading tokenizer resources ensures consistent and error-free NLP preprocessing across environments\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# used Pandas and NumPy for data handling, Matplotlib and Seaborn for visualization, Regex for text cleaning, and NLTK for NLP preprocessing. <punkt_tab> to avoid tokenizer lookup errors in newer NLTK environments, ensuring pipeline stability across platforms."
      ],
      "metadata": {
        "id": "EZMP-EuQZQ3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba8c910-da40-4457-c52c-5c733d8eb397"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# LOAD DATASET\n",
        "# ============================================================\n",
        "df = pd.read_csv(\n",
        "    'yelp_labelled.txt',\n",
        "    sep='\\t',\n",
        "    header=None,\n",
        "    names=['review', 'sentiment']\n",
        ")\n",
        "\n",
        "print(\"Dataset Loaded Successfully!\")\n",
        "print(df.head(20))\n",
        "\n",
        "#Data set loaded and sentiment \"1\" is positive sentiment and \"0\" is negative sentiment"
      ],
      "metadata": {
        "id": "uHhUT5jdZQ0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209ed7b2-5b69-4831-9545-55d8d02d09e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded Successfully!\n",
            "                                               review  sentiment\n",
            "0                            Wow... Loved this place.          1\n",
            "1                                  Crust is not good.          0\n",
            "2           Not tasty and the texture was just nasty.          0\n",
            "3   Stopped by during the late May bank holiday of...          1\n",
            "4   The selection on the menu was great and so wer...          1\n",
            "5      Now I am getting angry and I want my damn pho.          0\n",
            "6               Honeslty it didn't taste THAT fresh.)          0\n",
            "7   The potatoes were like rubber and you could te...          0\n",
            "8                           The fries were great too.          1\n",
            "9                                      A great touch.          1\n",
            "10                           Service was very prompt.          1\n",
            "11                                 Would not go back.          0\n",
            "12  The cashier had no care what so ever on what I...          0\n",
            "13  I tried the Cape Cod ravoli, chicken,with cran...          1\n",
            "14  I was disgusted because I was pretty sure that...          0\n",
            "15  I was shocked because no signs indicate cash o...          0\n",
            "16                                Highly recommended.          1\n",
            "17             Waitress was a little slow in service.          0\n",
            "18  This place is not worth your time, let alone V...          0\n",
            "19                               did not like at all.          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "A8tbc8atZQx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974a56c2-a80e-4816-ed22-de7ff83e446d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "\n",
        "# used df.info() to quickly validate the dataset schema, confirm there were no null values, and verify that the review text and sentiment labels had appropriate data types before preprocessing"
      ],
      "metadata": {
        "id": "SnfiBMrXZQuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d537155f-58d5-41c0-a418-215fa5817ed2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     1000 non-null   object\n",
            " 1   sentiment  1000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 15.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull()\n",
        "\n",
        "#used df.isnull().sum() to confirm that the dataset contained no null values in either the review or sentiment columns before applying NLP preprocessing"
      ],
      "metadata": {
        "id": "25otIq3uZQrS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "ae7d0daa-a1ae-46c3-d47c-81a7f434edd0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     review  sentiment\n",
              "0     False      False\n",
              "1     False      False\n",
              "2     False      False\n",
              "3     False      False\n",
              "4     False      False\n",
              "..      ...        ...\n",
              "995   False      False\n",
              "996   False      False\n",
              "997   False      False\n",
              "998   False      False\n",
              "999   False      False\n",
              "\n",
              "[1000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b63d4ad-f23a-49dc-ac75-cbe60e1a00e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b63d4ad-f23a-49dc-ac75-cbe60e1a00e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b63d4ad-f23a-49dc-ac75-cbe60e1a00e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b63d4ad-f23a-49dc-ac75-cbe60e1a00e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#used df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()\n",
        "# no missing text - reviews and no missing sentiment lables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "wHf0laZXmJ9J",
        "outputId": "b8d3cfb2-b4b3-42db-9b05-8ec406a022a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review       0\n",
              "sentiment    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>review</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "N34H7460mPBq",
        "outputId": "a1d4ff8c-bc08-4787-aee0-6e1d9c76cbeb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "1    500\n",
              "0    500\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='sentiment',data=df)\n",
        "\n",
        "# The dataset is well-balanced, so no resampling or class-weight adjustment is required."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "LqYdlyHtmetD",
        "outputId": "caa5c72f-6453-4d42-cb0a-26acaaf19465"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='sentiment', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['review length'] = df['review'].apply(len)"
      ],
      "metadata": {
        "id": "8kxU_iasmv76"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "1msfBoq6nPkv",
        "outputId": "1dbd881d-c333-49fa-83ba-786578ffab5e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                review  sentiment  \\\n",
              "0                             Wow... Loved this place.          1   \n",
              "1                                   Crust is not good.          0   \n",
              "2            Not tasty and the texture was just nasty.          0   \n",
              "3    Stopped by during the late May bank holiday of...          1   \n",
              "4    The selection on the menu was great and so wer...          1   \n",
              "..                                                 ...        ...   \n",
              "995  I think food should have flavor and texture an...          0   \n",
              "996                           Appetite instantly gone.          0   \n",
              "997  Overall I was not impressed and would not go b...          0   \n",
              "998  The whole experience was underwhelming, and I ...          0   \n",
              "999  Then, as if I hadn't wasted enough of my life ...          0   \n",
              "\n",
              "     review length  \n",
              "0               24  \n",
              "1               18  \n",
              "2               41  \n",
              "3               87  \n",
              "4               59  \n",
              "..             ...  \n",
              "995             66  \n",
              "996             24  \n",
              "997             50  \n",
              "998             91  \n",
              "999            134  \n",
              "\n",
              "[1000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ac3b204-d3c9-4e5a-90b1-61a1c936b1eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>I think food should have flavor and texture an...</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Appetite instantly gone.</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Overall I was not impressed and would not go b...</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The whole experience was underwhelming, and I ...</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
              "      <td>0</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ac3b204-d3c9-4e5a-90b1-61a1c936b1eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ac3b204-d3c9-4e5a-90b1-61a1c936b1eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ac3b204-d3c9-4e5a-90b1-61a1c936b1eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_6b5f72a7-4eb6-4334-b8a1-9d01fb993ec0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6b5f72a7-4eb6-4334-b8a1-9d01fb993ec0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 996,\n        \"samples\": [\n          \"They were excellent.\",\n          \"Your servers suck, wait, correction, our server Heimer sucked.\",\n          \"Will be back again!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32,\n        \"min\": 11,\n        \"max\": 149,\n        \"num_unique_values\": 134,\n        \"samples\": [\n          122,\n          113\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['review length'],bins=30)\n",
        "\n",
        "# eview length to understand text distribution and to select an appropriate maximum sequence length, ensuring efficient padding without unnecessary truncation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "V8j8vVLYnQqZ",
        "outputId": "8b6fe19c-100a-410e-b7b2-b607d7ee5f72"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='review length', ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEXT PREPROCESSING**"
      ],
      "metadata": {
        "id": "B7joHmDtnrAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# REQUIRED IMPORTS FOR TEXT PREPROCESSING\n",
        "# ============================================================\n",
        "import re                          # for regular expressions (removing special characters)\n",
        "from nltk.corpus import stopwords  # to get English stopwords\n",
        "from nltk.tokenize import word_tokenize  # for splitting text into words, this is first step before vectorization\n",
        "\n",
        "# ============================================================\n",
        "# TEXT PREPROCESSING\n",
        "# ============================================================\n",
        "stop_words = set(stopwords.words('english'))  # load English stopwords\n",
        "stop_words\n",
        "\n",
        "# Stopwords occur very frequently but add little semantic or sentiment value. Removing them reduces noise, vocabulary size, and improves model learning efficiency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVp3Uxlsne4Q",
        "outputId": "cd15de02-adac-4a9e-df3b-ab8f588d36ac"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " \"he's\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " \"i've\",\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " \"we've\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()  # convert all text to lowercase, it ensures consistency and avoids duplicate word representations\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # remove punctuation and special characters\n",
        "    tokens = word_tokenize(text)  # split text into individual words (tokens), Tokenization converts raw text into analyzable word units\n",
        "    stop_words_refined = stop_words - set(['not', 'no'])  # keep negations 'not' and 'no'\n",
        "    tokens = [word for word in tokens if word not in stop_words_refined]  # remove stopwords\n",
        "    return ' '.join(tokens)  # join tokens back into a cleaned string\n",
        "\n",
        "    # built a custom text preprocessing function that lowercases text, removes special characters, tokenizes words, eliminates stopwords while preserving negations like not and no, and reconstructs clean sentences for modeling"
      ],
      "metadata": {
        "id": "C76vfQT3nwio"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_review'] = df['review'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "msspEdkgoqzD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "O-IAZOOCo66x",
        "outputId": "57555053-b6b7-4d72-da71-0aae4dfca0d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                review  sentiment  \\\n",
              "0                             Wow... Loved this place.          1   \n",
              "1                                   Crust is not good.          0   \n",
              "2            Not tasty and the texture was just nasty.          0   \n",
              "3    Stopped by during the late May bank holiday of...          1   \n",
              "4    The selection on the menu was great and so wer...          1   \n",
              "..                                                 ...        ...   \n",
              "995  I think food should have flavor and texture an...          0   \n",
              "996                           Appetite instantly gone.          0   \n",
              "997  Overall I was not impressed and would not go b...          0   \n",
              "998  The whole experience was underwhelming, and I ...          0   \n",
              "999  Then, as if I hadn't wasted enough of my life ...          0   \n",
              "\n",
              "     review length                                     cleaned_review  \n",
              "0               24                                    wow loved place  \n",
              "1               18                                     crust not good  \n",
              "2               41                            not tasty texture nasty  \n",
              "3               87  stopped late may bank holiday rick steve recom...  \n",
              "4               59                        selection menu great prices  \n",
              "..             ...                                                ...  \n",
              "995             66                  think food flavor texture lacking  \n",
              "996             24                            appetite instantly gone  \n",
              "997             50            overall not impressed would not go back  \n",
              "998             91  whole experience underwhelming think well go n...  \n",
              "999            134  hadnt wasted enough life poured salt wound dra...  \n",
              "\n",
              "[1000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c772dc7-b1cc-441f-b9e3-e3cbf0c80b10\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review length</th>\n",
              "      <th>cleaned_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>wow loved place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>crust not good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>not tasty texture nasty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>stopped late may bank holiday rick steve recom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>selection menu great prices</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>I think food should have flavor and texture an...</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>think food flavor texture lacking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Appetite instantly gone.</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>appetite instantly gone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Overall I was not impressed and would not go b...</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>overall not impressed would not go back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The whole experience was underwhelming, and I ...</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>whole experience underwhelming think well go n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
              "      <td>0</td>\n",
              "      <td>134</td>\n",
              "      <td>hadnt wasted enough life poured salt wound dra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c772dc7-b1cc-441f-b9e3-e3cbf0c80b10')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c772dc7-b1cc-441f-b9e3-e3cbf0c80b10 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c772dc7-b1cc-441f-b9e3-e3cbf0c80b10');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_99509b83-42a2-4d97-a7d7-d29d80d4ed6e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_99509b83-42a2-4d97-a7d7-d29d80d4ed6e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 996,\n        \"samples\": [\n          \"They were excellent.\",\n          \"Your servers suck, wait, correction, our server Heimer sucked.\",\n          \"Will be back again!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32,\n        \"min\": 11,\n        \"max\": 149,\n        \"num_unique_values\": 134,\n        \"samples\": [\n          122,\n          113\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 991,\n        \"samples\": [\n          \"wont go back\",\n          \"truly unbelievably good glad went back\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show sample before vs after cleaning\n",
        "print(\"\\nBefore vs After Cleaning:\\n\")\n",
        "for i in range(5): # Iterates over the first 5 reviews\n",
        "    print(\"Original :\", df['review'][i])        # original review\n",
        "    print(\"Cleaned  :\", df['cleaned_review'][i])  # cleaned review after preprocessing\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akP7OQDEo7pv",
        "outputId": "9ba39bd0-1d9d-42c9-fa3d-02bb0e5cf25a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Before vs After Cleaning:\n",
            "\n",
            "Original : Wow... Loved this place.\n",
            "Cleaned  : wow loved place\n",
            "------------------------------------------------------------\n",
            "Original : Crust is not good.\n",
            "Cleaned  : crust not good\n",
            "------------------------------------------------------------\n",
            "Original : Not tasty and the texture was just nasty.\n",
            "Cleaned  : not tasty texture nasty\n",
            "------------------------------------------------------------\n",
            "Original : Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\n",
            "Cleaned  : stopped late may bank holiday rick steve recommendation loved\n",
            "------------------------------------------------------------\n",
            "Original : The selection on the menu was great and so were the prices.\n",
            "Cleaned  : selection menu great prices\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Building**"
      ],
      "metadata": {
        "id": "gZ29pQENpd08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input â†’ Embedding â†’ Multi-Head Attention â†’ Global Avg Pool â†’ Dense\n",
        "# TensorFlow Keras Functional API was used to build an attention-based sentiment classification model, with tokenization, padding, and class balancing support.\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model # # Enables building custom neural network architectures using the Keras Functional API\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, GlobalAveragePooling1D, MultiHeadAttention\n",
        "# Provides layers for defining model inputs, word embeddings, attention mechanism, pooling, and final classification\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # # Converts cleaned text into numerical sequences by building a vocabulary\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # Ensures all text sequences have uniform length for batch model training\n",
        "from sklearn.model_selection import train_test_split # Splits data into training and testing sets\n",
        "from sklearn.utils import class_weight\n",
        "#  Computes class weights to handle potential class imbalance during model training"
      ],
      "metadata": {
        "id": "L3m30yoapIhZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5000 # Maximum number of unique words to keep in the tokenizer vocabulary\n",
        "max_len = 50 # Maximum length of each input sequence after padding/truncating"
      ],
      "metadata": {
        "id": "-Wogbk6Hp4-B"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size,oov_token = '<OOV>')"
      ],
      "metadata": {
        "id": "kumvRf0LqTDi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag52l60Vqxj1",
        "outputId": "e8482d78-ba80-4620-85a0-644424b729bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.legacy.preprocessing.text.Tokenizer at 0x7eda7d0ecbf0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(df['cleaned_review'])"
      ],
      "metadata": {
        "id": "3DXuQd1qqynI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tokenizer.texts_to_sequences(df['cleaned_review'])"
      ],
      "metadata": {
        "id": "uya2PRi4rJob"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NwQ_K5h4rMid",
        "outputId": "79aa3393-611a-4cd3-814c-e20c5de27fee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[333, 93, 4],\n",
              " [484, 3, 5],\n",
              " [3, 80, 334, 335],\n",
              " [485, 486, 205, 779, 780, 781, 782, 336, 93],\n",
              " [94, 54, 7, 95],\n",
              " [124, 783, 65, 262, 178],\n",
              " [784, 66, 67, 59],\n",
              " [337, 9, 785, 49, 179, 47, 786, 11, 206, 787],\n",
              " [108, 7],\n",
              " [7, 487],\n",
              " [6, 788],\n",
              " [14, 3, 10, 8],\n",
              " [488, 21, 338, 15, 50, 81, 489, 789, 125],\n",
              " [154, 790, 791, 792, 793, 794],\n",
              " [795, 31, 126, 490, 491],\n",
              " [796, 21, 797, 798, 799],\n",
              " [263, 339],\n",
              " [127, 96, 82, 6],\n",
              " [4, 3, 97, 11, 492, 800, 26],\n",
              " [3, 9],\n",
              " [801, 802],\n",
              " [2, 24],\n",
              " [6, 17, 493],\n",
              " [49, 338, 803, 804, 340],\n",
              " [805],\n",
              " [494, 806, 495, 807, 808, 496, 5],\n",
              " [18, 341, 55, 207],\n",
              " [809, 342, 7, 497, 810, 264, 19, 32],\n",
              " [128, 180, 33, 2, 343, 208, 22, 2, 811, 181, 812, 265, 129, 9, 344, 498],\n",
              " [60, 266, 345],\n",
              " [17, 813, 9, 74, 108, 130, 814, 499, 155],\n",
              " [9, 815, 816],\n",
              " [156, 4, 817, 49, 3, 818],\n",
              " [500, 9, 5, 209, 4, 819, 501, 502, 820, 2, 503, 267, 268],\n",
              " [131, 9, 4, 157],\n",
              " [821, 68, 22, 504],\n",
              " [822, 210, 5, 95],\n",
              " [182, 6, 158, 47, 83, 9, 823, 109, 11, 28, 110],\n",
              " [48, 269, 824, 505],\n",
              " [6, 346],\n",
              " [183, 184, 347],\n",
              " [3, 155, 5, 75, 14, 825, 270],\n",
              " [185, 506, 826, 348, 5, 507, 827, 828, 66, 65, 34, 829, 124, 211],\n",
              " [830, 508, 69, 159, 831, 7, 6],\n",
              " [349, 832, 833, 60, 111, 509, 834],\n",
              " [132, 9, 835, 836, 212, 837],\n",
              " [41, 2, 262, 838],\n",
              " [74, 5, 213, 160, 133],\n",
              " [65, 112, 10, 839],\n",
              " [161, 350, 55, 350, 351, 80, 352, 353, 840],\n",
              " [61, 354, 271, 841, 184, 162, 23, 510, 214],\n",
              " [28, 265, 35, 511, 272, 186, 842, 110],\n",
              " [843, 844, 5],\n",
              " [187, 512, 513, 514, 215, 20, 514, 16, 188, 2],\n",
              " [515, 216],\n",
              " [93, 845, 217, 7, 2, 163, 846, 54],\n",
              " [273, 516, 517, 518, 26, 134, 847, 519, 22],\n",
              " [3, 42, 218, 9, 135, 848, 219, 849],\n",
              " [55, 133, 355, 98, 3, 850, 520, 356, 160],\n",
              " [521, 851, 3, 521, 852, 220],\n",
              " [274, 51, 522, 357, 853, 854, 221, 36],\n",
              " [4, 855, 56, 523],\n",
              " [856, 857, 25],\n",
              " [858, 43, 10, 8],\n",
              " [524, 156, 4],\n",
              " [7, 2, 6, 216, 210, 113, 859, 860],\n",
              " [57, 7, 11, 861, 862],\n",
              " [863, 8, 358, 11, 81, 24],\n",
              " [44, 2, 864, 18, 525, 359, 526, 222, 360],\n",
              " [7, 62, 527, 7],\n",
              " [155, 865, 135, 866, 136, 275, 867, 76, 528, 361],\n",
              " [12, 12, 5, 276, 11],\n",
              " [6, 529],\n",
              " [128, 223, 530, 33, 868, 164, 869, 870],\n",
              " [362, 531, 4, 14, 532, 162, 871, 66, 533, 872, 873],\n",
              " [520, 137, 138, 874, 534, 45],\n",
              " [136, 70, 41, 224, 6],\n",
              " [225, 189, 108, 5, 535, 45],\n",
              " [277, 358, 11, 29, 114, 84, 31, 5],\n",
              " [42, 5, 2, 26, 83, 875, 536, 165, 537, 46, 276, 538],\n",
              " [99, 9, 876, 539, 877, 878, 85, 63, 540, 278, 541],\n",
              " [363, 4, 879, 9, 226, 542, 880, 136, 543, 165],\n",
              " [881, 544, 213, 86],\n",
              " [4],\n",
              " [882, 883, 279, 884, 67, 9, 545, 885, 886, 887, 546, 547, 226],\n",
              " [37, 178, 888, 364, 365, 280, 139],\n",
              " [182, 526, 115, 889, 47, 52, 890, 891],\n",
              " [50, 2, 24],\n",
              " [892, 548],\n",
              " [100, 59, 25],\n",
              " [893, 894, 227, 140, 30],\n",
              " [9, 12, 895, 366, 367, 368, 896, 897, 898, 540, 366],\n",
              " [18, 185, 899, 900, 18, 15, 901, 902],\n",
              " [13, 116, 84],\n",
              " [50, 549, 549, 369, 550],\n",
              " [45, 18, 10],\n",
              " [8],\n",
              " [2, 370, 371],\n",
              " [3, 5],\n",
              " [161, 372, 551, 12, 5, 2],\n",
              " [69, 77, 156, 373, 903, 552, 553, 904, 554, 555, 556, 87, 101, 554, 10],\n",
              " [5, 132, 158, 281, 206, 905, 906, 99],\n",
              " [13, 84, 166, 167, 3, 282],\n",
              " [93, 907, 160, 283, 908, 354, 184, 189, 117, 25],\n",
              " [20, 53, 909],\n",
              " [76, 910, 77, 911],\n",
              " [2, 25, 557, 159, 912, 44, 7, 155],\n",
              " [374, 163, 375, 558],\n",
              " [10, 8, 88, 284],\n",
              " [913, 5],\n",
              " [228, 71, 559, 914, 376, 915, 3, 5],\n",
              " [274, 916, 560, 35, 917, 2, 918, 72, 377],\n",
              " [12, 77, 229, 22, 43, 97, 269],\n",
              " [23, 141, 184],\n",
              " [5, 95],\n",
              " [190],\n",
              " [31, 561],\n",
              " [29, 53, 102],\n",
              " [285, 185, 919, 64],\n",
              " [378, 42, 379, 267, 920, 4, 921, 30, 142, 227],\n",
              " [16, 89, 4, 922, 191, 923, 2, 15, 230, 562, 563, 924],\n",
              " [60, 6, 564, 274, 925],\n",
              " [6, 380, 127, 19],\n",
              " [926, 286, 64, 927, 928, 64, 13, 60, 231, 143, 13, 64, 929, 15, 230],\n",
              " [232, 565, 930, 233, 33, 5, 71, 4, 12, 234, 144, 78],\n",
              " [931, 32, 932, 53, 566, 933],\n",
              " [86, 3, 934, 4, 935, 936, 16, 65, 235, 11, 41, 937, 168, 287],\n",
              " [938, 2, 6, 169],\n",
              " [381, 236],\n",
              " [43, 97, 939, 382, 288, 567, 236, 88, 11, 27, 26],\n",
              " [4, 62, 125, 192, 2],\n",
              " [940, 941, 103],\n",
              " [5, 94, 2, 942, 943, 944, 112, 945, 52, 568, 383, 569, 384, 80, 289],\n",
              " [193, 145],\n",
              " [25, 946, 570, 5, 571, 290, 385, 228, 947, 948, 38],\n",
              " [7, 386, 291, 5, 90, 109, 386, 3, 949, 950],\n",
              " [170, 951, 116],\n",
              " [20, 13, 572, 2, 26],\n",
              " [237, 145, 12, 118, 387, 14, 37, 573, 952, 26],\n",
              " [292, 18, 388, 47, 12, 7, 54, 953],\n",
              " [16],\n",
              " [158, 72, 281, 19, 574, 389, 35],\n",
              " [272, 390, 114, 39, 2, 6],\n",
              " [495, 575, 42, 954, 955, 72, 80],\n",
              " [23, 956, 957, 958, 83, 9, 194, 959, 576, 2],\n",
              " [577, 119, 4, 45, 578],\n",
              " [54, 57, 960, 2, 68, 46, 6, 237, 82],\n",
              " [6, 96, 82, 293, 191, 294, 111, 217, 2, 99, 82, 579],\n",
              " [113, 136, 295],\n",
              " [391, 158, 296, 157, 961, 208, 962, 35],\n",
              " [963, 28, 964, 120, 580, 238, 133, 233],\n",
              " [7, 22, 965, 297],\n",
              " [104, 966, 967, 36, 968],\n",
              " [969, 28, 55, 392],\n",
              " [970, 7, 68, 971],\n",
              " [32, 19, 581, 57, 119],\n",
              " [393, 582, 298, 120, 81, 163, 184, 45, 45, 972],\n",
              " [61, 973, 219, 48, 11, 239, 12, 103, 219, 146, 46, 974, 975, 394, 395, 396],\n",
              " [4, 5],\n",
              " [299, 195, 234, 583, 976, 120, 100, 61, 392],\n",
              " [28, 8, 277, 146, 977, 81, 3, 147],\n",
              " [238, 397],\n",
              " [54, 978, 584, 585],\n",
              " [240, 979],\n",
              " [22, 57, 241, 18, 63],\n",
              " [25],\n",
              " [4, 980, 20, 13, 231, 34, 300, 981, 171],\n",
              " [16, 10, 586, 5, 2],\n",
              " [29, 18, 398, 41],\n",
              " [242, 982, 983],\n",
              " [17, 61, 984, 985, 55, 986, 301, 351, 399, 243, 67],\n",
              " [12, 26, 380, 140, 400, 133, 987, 988, 587, 21, 95, 989],\n",
              " [990, 19],\n",
              " [991, 992, 993, 137, 3, 994, 575, 559],\n",
              " [100, 54, 995, 17, 996, 47, 24, 997, 401, 998],\n",
              " [999, 1000, 78, 1001, 402, 27, 3, 1002, 10, 8],\n",
              " [6, 1003, 157, 1004],\n",
              " [102, 1005, 1006, 1007, 487, 1008],\n",
              " [3, 1009, 1010, 43, 4, 90, 8, 109],\n",
              " [399, 244, 302, 36, 21, 20, 1011, 148, 91],\n",
              " [74, 134, 21, 73, 115, 344, 86, 74, 588, 21, 589, 73],\n",
              " [17, 590, 3, 1012, 8, 127, 591, 9, 1013, 273, 516],\n",
              " [1014, 398, 1015],\n",
              " [105, 592],\n",
              " [37, 4, 1016, 144, 65, 303, 403, 3, 404, 1017, 73],\n",
              " [61, 1018, 1019, 245, 1020, 17, 304],\n",
              " [2, 305, 361, 305, 49, 1021],\n",
              " [405, 406],\n",
              " [12, 9, 1022, 593],\n",
              " [17, 191, 121, 246, 407, 247, 47, 189, 172, 242, 1023, 1024, 1025, 5],\n",
              " [594, 562, 25, 2],\n",
              " [408, 364, 77],\n",
              " [91, 370, 20, 595, 1026],\n",
              " [55, 306, 245, 290, 212, 186, 596, 138, 1027],\n",
              " [27, 3, 12, 126, 1028, 1029, 13, 121, 409, 597, 1030, 300, 1031],\n",
              " [13, 4, 10, 80, 598, 178],\n",
              " [307, 375, 1032, 344, 1033],\n",
              " [29, 18, 410, 149, 599],\n",
              " [19, 32],\n",
              " [97, 308],\n",
              " [525, 5, 248, 4, 1034, 109, 411, 49, 1035],\n",
              " [2, 7, 1036],\n",
              " [181, 130, 66, 1037],\n",
              " [7, 412, 144],\n",
              " [6, 19, 1038],\n",
              " [5, 114, 144],\n",
              " [29, 1039, 146, 1040, 48, 196, 11, 29, 1041, 1042, 4],\n",
              " [60, 30, 15],\n",
              " [195, 78, 4],\n",
              " [348, 383, 1043, 1044, 1045, 600, 601, 413, 1046, 1047],\n",
              " [602, 18, 1048, 14, 603, 343, 126, 161, 342, 602, 1049, 1050],\n",
              " [221, 36, 249, 55, 511, 72, 99, 11, 122],\n",
              " [604, 93, 266, 1051],\n",
              " [40, 10, 8],\n",
              " [237, 80],\n",
              " [127, 5, 309],\n",
              " [414, 3, 5],\n",
              " [1052, 1053, 25],\n",
              " [197, 3, 97, 167],\n",
              " [2, 1054, 91, 1055],\n",
              " [605, 171, 214, 1056, 3, 148, 241, 605, 415, 16, 606, 1057, 279, 198],\n",
              " [6, 142, 404],\n",
              " [416, 607, 1058, 1059, 1060, 608, 609, 359, 1061, 417, 418, 208],\n",
              " [1062, 1063, 46, 310, 311, 610, 90],\n",
              " [199, 123, 3, 75, 73, 41],\n",
              " [93, 242, 1064, 1065],\n",
              " [1066, 1067],\n",
              " [312, 1068, 57, 150, 35, 83, 1069, 200],\n",
              " [1070, 17, 1071],\n",
              " [4, 48, 178, 24],\n",
              " [163, 30, 47, 4, 1072, 1073, 166],\n",
              " [2, 419, 41, 75, 188, 611, 1074, 1075, 1076, 111],\n",
              " [313, 420],\n",
              " [61, 612, 613, 44, 614, 1077, 1078, 1079, 1080, 1081, 1082, 81, 346],\n",
              " [7, 4, 421, 275, 594, 1083, 1084, 1085, 1086, 1087],\n",
              " [314, 113, 243, 56, 1088],\n",
              " [1089,\n",
              "  143,\n",
              "  615,\n",
              "  615,\n",
              "  98,\n",
              "  101,\n",
              "  143,\n",
              "  1090,\n",
              "  98,\n",
              "  422,\n",
              "  101,\n",
              "  143,\n",
              "  141,\n",
              "  1091,\n",
              "  418,\n",
              "  364,\n",
              "  1092],\n",
              " [239, 50, 14, 1093, 1094, 616, 1095, 117, 67, 1096, 67, 24],\n",
              " [3, 1097, 1098, 205, 617, 3, 126, 10, 8, 139],\n",
              " [279, 159, 1099, 103, 224, 6],\n",
              " [187, 16, 235, 11, 201],\n",
              " [137, 138, 1100],\n",
              " [11, 161, 22, 618, 388, 21, 519],\n",
              " [72, 377, 199, 17, 619, 1101, 123],\n",
              " [9, 1102, 143, 423, 296, 34, 4],\n",
              " [275, 128, 315, 223, 36, 90, 20, 424],\n",
              " [170, 425, 1103, 312],\n",
              " [42, 53, 1104, 71, 4, 76, 26],\n",
              " [1105, 620, 75, 621, 1106],\n",
              " [1107, 576, 6, 426, 21, 1108, 1109, 1110, 310, 40, 46, 8],\n",
              " [250, 12, 7, 111],\n",
              " [164, 1111, 1112],\n",
              " [350, 351, 622, 425],\n",
              " [131, 16, 51, 14, 148, 1113, 4, 47, 623, 624, 1114, 149],\n",
              " [58, 5, 1115, 98, 80],\n",
              " [1116, 110, 6, 31, 251],\n",
              " [77, 6],\n",
              " [45, 1117, 603, 1118, 243, 56, 314],\n",
              " [89, 150],\n",
              " [1119, 1120, 73],\n",
              " [411, 4, 625, 129],\n",
              " [572, 26, 3, 15, 1121, 1122, 626, 357],\n",
              " [22, 102, 1123],\n",
              " [5, 6, 119, 504, 564],\n",
              " [218, 59, 427, 515],\n",
              " [627, 428, 628],\n",
              " [6, 3, 629, 199],\n",
              " [1124, 173, 1125, 202, 2, 134, 25, 11],\n",
              " [5, 547, 396],\n",
              " [1126, 1127, 630, 372, 1128, 39],\n",
              " [1129, 1130, 631],\n",
              " [85, 10, 252, 2],\n",
              " [85, 282],\n",
              " [485, 4, 1131, 1132, 19, 285, 32],\n",
              " [1133, 19, 5, 316],\n",
              " [29, 53, 3, 1134, 632, 317, 1135, 38, 1136, 178],\n",
              " [379, 429, 6, 430],\n",
              " [1137, 633, 66, 1138, 115, 333, 73],\n",
              " [51, 3],\n",
              " [1139, 55, 31, 86, 3, 124],\n",
              " [76, 634, 74, 174, 336, 3, 39],\n",
              " [6, 1140],\n",
              " [104, 104],\n",
              " [4, 3, 68, 71, 3, 68, 22],\n",
              " [14, 43, 92, 306, 45, 58],\n",
              " [7, 58, 635],\n",
              " [248, 76, 252, 1141, 1142],\n",
              " [104, 180, 116, 49, 194, 636, 70, 53, 247],\n",
              " [4, 24],\n",
              " [637, 1143, 1144, 1145, 272, 39, 4],\n",
              " [104, 136, 638, 18, 44, 199, 431, 118, 129, 35, 28, 639],\n",
              " [16, 89, 82],\n",
              " [32, 7, 2, 383, 304, 130, 94],\n",
              " [307, 640, 39, 40, 8, 641, 318],\n",
              " [66, 89, 432, 288, 49, 642, 25],\n",
              " [33, 1146, 59, 222, 1147, 338],\n",
              " [10, 319, 320, 433, 1148, 434, 89, 643, 11, 165, 634, 74, 1149, 435],\n",
              " [37, 291, 100, 54, 97],\n",
              " [18, 140, 4],\n",
              " [2, 103, 6, 5],\n",
              " [5, 130, 292, 94, 5, 2, 94],\n",
              " [434, 436, 233, 183, 644, 253, 1150],\n",
              " [189, 1151, 91, 301, 49, 105, 1152, 118, 172, 1153, 105, 129, 437],\n",
              " [2, 12, 1154],\n",
              " [5, 1155],\n",
              " [1156, 1157, 18, 198, 101, 1158],\n",
              " [18, 15, 10, 8],\n",
              " [42, 239, 9, 10, 8, 85, 33, 560, 1159, 6, 18, 236],\n",
              " [645, 573, 1160, 1161, 429, 646],\n",
              " [3, 254, 5],\n",
              " [77, 2],\n",
              " [61, 647, 1162, 1163, 28, 1164],\n",
              " [2, 5],\n",
              " [18, 46, 8],\n",
              " [7, 2, 167, 438, 68, 439, 47],\n",
              " [1165, 648, 649, 145],\n",
              " [424, 174, 650, 1166, 4, 651, 66, 606, 1167, 1168, 1169, 531],\n",
              " [8, 5, 1170, 1171, 652, 255, 653, 179, 1172, 8, 226, 1173],\n",
              " [293, 151, 35, 186, 241, 152, 302, 85, 10, 252],\n",
              " [246, 47, 1174],\n",
              " [1175, 6],\n",
              " [17, 108, 654, 655, 60, 108, 29, 15],\n",
              " [6, 1176, 2, 5, 402],\n",
              " [421, 1177, 639, 1178, 24, 87],\n",
              " [440, 4, 166, 1179],\n",
              " [656, 1180, 1181, 225, 337, 1182],\n",
              " [40, 39],\n",
              " [49, 657, 1183, 205, 150, 53, 131, 137, 81, 5],\n",
              " [10, 173, 118, 231, 29, 18, 658, 22, 551, 320, 408, 116, 441, 1184],\n",
              " [659, 44, 247, 397, 44, 211, 660, 55],\n",
              " [217, 3, 442, 155, 16, 57, 1185, 58, 1186, 1187],\n",
              " [1188, 1189, 5, 524, 76, 8],\n",
              " [77, 6, 443, 102],\n",
              " [100, 561],\n",
              " [37, 4],\n",
              " [7, 6, 2],\n",
              " [48, 577, 318, 321, 1190, 1191, 3, 1192, 1193, 1194],\n",
              " [74, 44, 600, 1195, 1196, 74, 285, 39],\n",
              " [661, 2, 1197],\n",
              " [164, 203, 4],\n",
              " [1198, 164, 200, 1199],\n",
              " [117, 266, 13, 7],\n",
              " [322, 59, 98, 662, 9, 203, 229],\n",
              " [97, 1200, 1201],\n",
              " [94, 105, 60, 29, 658, 1202, 418],\n",
              " [31, 5, 130, 94],\n",
              " [4, 9, 1203, 53],\n",
              " [1204, 102, 313, 59, 523, 1205, 286, 1206, 64],\n",
              " [135, 56, 663, 664, 246, 1207],\n",
              " [230, 665, 70, 11, 2, 25],\n",
              " [244, 101, 666, 36, 667, 319, 186],\n",
              " [106],\n",
              " [279, 398, 444, 200],\n",
              " [1208, 148, 223, 530, 668, 669],\n",
              " [25],\n",
              " [5, 161, 32, 1209, 442, 1210, 228, 670],\n",
              " [1211, 1212, 1213, 64, 4, 1214, 1215, 240, 88, 284, 26],\n",
              " [57, 671, 163, 2, 25],\n",
              " [13, 222, 29, 15, 672],\n",
              " [445, 88, 446, 23],\n",
              " [84, 197, 2, 1216, 86],\n",
              " [430, 96, 22, 13, 2, 15, 153],\n",
              " [31, 447, 14, 50],\n",
              " [43, 1217, 655, 168, 8, 415, 311, 448, 1218],\n",
              " [69, 7, 316, 1219, 323, 1220, 110],\n",
              " [449, 536, 2, 1221, 72, 2],\n",
              " [373, 416, 607, 324, 673],\n",
              " [14, 90, 8, 71, 1222, 26],\n",
              " [32, 7, 169, 7],\n",
              " [450, 135, 56],\n",
              " [186, 451, 1223, 149, 211, 1224, 120],\n",
              " [1225, 1226],\n",
              " [140, 1227, 1228, 1229, 578, 674],\n",
              " [1230, 91, 62, 565, 9, 1231, 675, 452, 1232, 644, 676, 37],\n",
              " [453, 276, 192, 13],\n",
              " [13, 264, 166, 173],\n",
              " [128, 8, 201, 44, 1233],\n",
              " [405, 677, 166, 4, 24],\n",
              " [145, 1234, 193],\n",
              " [32, 3, 19, 63, 70, 191, 187, 21, 20, 38, 1235, 1236, 48, 221, 36],\n",
              " [40, 8],\n",
              " [7, 1237],\n",
              " [6, 1238, 43, 92, 1239],\n",
              " [2, 106],\n",
              " [18, 15, 10, 8, 454, 118, 111, 678],\n",
              " [16, 92, 415, 679, 1240, 680, 1241],\n",
              " [90, 8, 109, 11, 27, 26],\n",
              " [4, 450, 20, 433, 1242, 2],\n",
              " [1243],\n",
              " [1244, 99, 8, 598, 88, 11],\n",
              " [65, 403, 203, 1245, 2, 139, 4],\n",
              " [1246, 90, 587, 78, 1247, 1248, 78, 263, 92, 4, 681, 171],\n",
              " [394, 70, 1249, 30, 57, 7],\n",
              " [363, 233, 682, 152, 48, 26, 84, 30],\n",
              " [6, 103, 95, 31, 255, 293, 26, 1250, 162, 1251, 1252, 683, 1253],\n",
              " [1254, 2, 304, 1255, 1256, 164, 1257, 1258, 138, 9, 1259, 1260, 1261, 1262],\n",
              " [27, 105, 20, 111, 15, 10, 1263, 3, 9],\n",
              " [455, 58, 57, 234, 684, 7, 161, 137, 325, 1264],\n",
              " [6, 107, 175, 102, 23, 198],\n",
              " [160, 685, 6, 686],\n",
              " [20, 687, 326],\n",
              " [131, 39, 68, 2, 1265],\n",
              " [16, 1266, 89, 27, 124, 1267],\n",
              " [7, 4, 34, 1268, 96, 659, 688, 1269, 1270, 1271, 297, 171],\n",
              " [277, 48, 67, 1272, 1273, 121, 409, 179, 15, 232, 314],\n",
              " [186, 1274],\n",
              " [168, 43, 122],\n",
              " [2, 12, 5, 44, 241, 1275, 251],\n",
              " [6, 77],\n",
              " [456, 235, 11],\n",
              " [16, 89, 285, 13, 1276, 317],\n",
              " [90, 1277, 287, 152, 682],\n",
              " [6, 113, 21, 56],\n",
              " [689, 40, 39],\n",
              " [148, 96, 41, 6, 2, 346],\n",
              " [319, 690, 34, 484, 1278, 81, 1279],\n",
              " [691, 507],\n",
              " [12, 256, 165],\n",
              " [48, 11, 46, 51, 371, 692, 457],\n",
              " [69, 23, 38, 309, 591, 96, 498, 327, 617, 693, 19, 694],\n",
              " [204, 1280, 454, 1281, 59, 23, 334, 67],\n",
              " [1282, 133, 88, 110, 323, 1283, 1284, 1285, 452, 1286, 1287],\n",
              " [1288, 85, 38, 449, 638, 1289, 1290],\n",
              " [695, 154, 9, 4, 221, 70, 51, 194],\n",
              " [696],\n",
              " [21, 624],\n",
              " [170, 5, 58, 27, 1291, 1292],\n",
              " [158, 1293],\n",
              " [1294, 136, 1295, 1296],\n",
              " [697, 22, 250, 29, 15, 90, 1297],\n",
              " [18, 90],\n",
              " [93, 698],\n",
              " [6, 209, 19],\n",
              " [61, 1298, 128, 328, 36, 58, 101, 221, 36],\n",
              " [1299, 77],\n",
              " [216, 1300, 1301, 298, 699, 1302, 1303, 1304],\n",
              " [43, 90, 8],\n",
              " [9, 1305, 620, 662, 9, 176],\n",
              " [333, 141, 25],\n",
              " [368, 3, 502, 190],\n",
              " [168, 148, 310, 204, 1306, 268],\n",
              " [239, 37, 10, 8],\n",
              " [700, 1307, 22, 163, 1308],\n",
              " [164, 200],\n",
              " [120, 701, 393, 155, 25],\n",
              " [3, 1309, 702, 1310, 1311, 242, 458, 1312],\n",
              " [3, 8],\n",
              " [98, 220],\n",
              " [2, 25, 141, 75, 126, 278, 1313, 1314, 62],\n",
              " [1315, 64, 160, 356, 7, 1316, 73],\n",
              " [16, 51, 45, 46, 8, 257, 122],\n",
              " [2, 1317],\n",
              " [173, 71, 1318, 43, 179, 1319, 5, 2, 41, 2, 1320, 41, 2],\n",
              " [410],\n",
              " [196, 294, 70, 114, 41],\n",
              " [52, 306, 1321, 703, 52, 115, 15, 230],\n",
              " [2, 5, 256, 109, 1322, 1323, 1324, 1325, 1326, 197, 175, 1327, 1328],\n",
              " [1329, 51, 7],\n",
              " [13, 1330, 704, 1331],\n",
              " [93, 4],\n",
              " [43, 3, 97, 294, 705],\n",
              " [1332, 245, 290, 622, 1333, 1334, 1335, 1336, 59, 75],\n",
              " [27, 1337, 11, 258, 144],\n",
              " [329, 60],\n",
              " [162, 12, 138, 23, 119],\n",
              " [2, 430, 95, 255],\n",
              " [16, 51, 168, 265, 8, 1338, 257, 122, 2],\n",
              " [1339, 291, 128, 302, 36, 706, 101, 459, 36, 33, 1340, 206, 1341, 248],\n",
              " [37, 707],\n",
              " [48, 26, 84, 3, 708],\n",
              " [5, 309],\n",
              " [20, 508, 1342, 49, 533, 1343],\n",
              " [7, 288, 112],\n",
              " [16, 235, 11],\n",
              " [456, 1344, 14, 42, 460, 10, 1345, 709, 1346, 1347, 630],\n",
              " [643, 385, 174, 74, 123],\n",
              " [188, 58, 412],\n",
              " [286, 45, 1348, 17, 356, 160],\n",
              " [710, 1349, 1350, 14, 328, 1351, 35, 1352],\n",
              " [93],\n",
              " [207, 461, 287, 654, 165, 66, 259, 199],\n",
              " [4, 1353, 1354, 26, 1355, 29, 1356, 449, 1357, 666, 395, 1358],\n",
              " [218, 1359, 1360, 183, 711, 712, 711, 712, 43, 3, 67, 59],\n",
              " [94, 2, 3, 13],\n",
              " [25, 134, 8],\n",
              " [419, 197, 175, 22, 380, 140, 270],\n",
              " [1361, 1362, 1363, 1364, 379, 1365, 713, 1366, 413, 1367],\n",
              " [16, 51, 8, 260, 11],\n",
              " [1368, 1369, 593, 574, 5, 1370],\n",
              " [79],\n",
              " [8, 118, 70, 122],\n",
              " [54, 42, 5, 496, 49, 3, 1371],\n",
              " [462, 1372, 1373, 133, 680, 1374, 187, 1375, 1376],\n",
              " [1377, 714, 463],\n",
              " [1378, 1379, 57, 234, 710],\n",
              " [1380, 1381],\n",
              " [1382, 17, 12, 5, 31, 323],\n",
              " [48, 1383, 30, 25],\n",
              " [1384, 52, 253, 64, 669, 11, 440],\n",
              " [127, 225, 1385],\n",
              " [17, 67, 1386, 1387, 1388, 668, 1389, 407, 24, 1390, 25],\n",
              " [239, 460, 34, 1391, 2, 170],\n",
              " [85, 50, 75, 5, 248, 4],\n",
              " [169, 304],\n",
              " [127, 329, 19],\n",
              " [14, 3, 92, 4],\n",
              " [131, 72, 147, 1392],\n",
              " [1393, 650, 1394],\n",
              " [106, 6],\n",
              " [1395, 39],\n",
              " [16, 42, 219, 37, 464, 649, 47, 1396, 330, 431],\n",
              " [113, 139, 152],\n",
              " [173, 13, 1397, 15],\n",
              " [584, 585, 17],\n",
              " [100, 107, 78],\n",
              " [2, 5, 1398, 176, 2],\n",
              " [308, 33],\n",
              " [48, 1399, 715, 583, 372, 23, 169, 119, 19, 32],\n",
              " [700, 3, 51, 10, 8],\n",
              " [424, 1400, 1401, 54, 91, 40, 39],\n",
              " [365, 132, 1402, 22],\n",
              " [1403, 465, 10],\n",
              " [1404, 1405, 87],\n",
              " [48, 11, 1406, 196],\n",
              " [289, 24],\n",
              " [1407, 1408, 1409, 3, 50, 566, 1410, 2, 1411, 36, 486],\n",
              " [62, 1412],\n",
              " [126, 91, 212, 38, 466, 1413, 1414, 1415, 1416, 548],\n",
              " [48, 11, 85, 63, 88],\n",
              " [557, 17, 23],\n",
              " [100, 5, 80],\n",
              " [4, 151, 295, 1417],\n",
              " [13, 4, 26, 116, 190, 244, 1418],\n",
              " [37, 203, 497, 2, 65, 716, 1419, 405, 422, 25, 1420, 717, 466, 139, 4],\n",
              " [106, 193],\n",
              " [103, 258, 22, 1421, 1422],\n",
              " [243, 56, 14, 113, 243, 56],\n",
              " [7, 64, 7, 348, 7, 283, 24, 467],\n",
              " [60, 1423, 15],\n",
              " [64, 183, 1424, 13, 718, 1425],\n",
              " [537, 277, 1426, 24, 431],\n",
              " [104, 1427, 36, 238, 378, 428, 1428, 208, 312, 249],\n",
              " [1429, 1430, 384, 367, 59],\n",
              " [40, 139, 46, 8, 38, 388],\n",
              " [21, 27, 46, 34, 189, 156, 1431, 491],\n",
              " [141, 75, 107, 719],\n",
              " [196, 78, 358, 11, 140, 152, 590, 10, 8],\n",
              " [3, 38, 1432, 133],\n",
              " [467, 142, 1433],\n",
              " [468, 28, 48, 11, 720, 284, 26, 49, 3, 443, 68, 2, 6],\n",
              " [12, 92, 4, 10, 252, 1434, 4],\n",
              " [23, 169],\n",
              " [14, 92, 1435, 469],\n",
              " [362, 470, 76, 78, 1436],\n",
              " [721, 720, 30, 1437, 318, 3, 5],\n",
              " [89, 3, 9, 387, 303],\n",
              " [240, 270],\n",
              " [51, 22, 1438, 3, 690, 185, 75],\n",
              " [722, 117, 25],\n",
              " [273, 4],\n",
              " [55, 86, 723, 724, 1439, 1440, 1441],\n",
              " [151, 149, 725],\n",
              " [5, 11],\n",
              " [471, 4, 7, 726, 216, 567, 1442, 71],\n",
              " [427, 210, 7, 67],\n",
              " [18, 10, 8, 4, 18, 15, 339, 4, 681],\n",
              " [217, 76, 8, 1443, 394, 70, 3, 38, 42, 727],\n",
              " [2, 25],\n",
              " [180, 170],\n",
              " [1444, 1445],\n",
              " [1446, 318, 327, 1447, 1448],\n",
              " [728, 1449, 182, 68, 193, 513, 1450, 45],\n",
              " [104, 104, 104],\n",
              " [17, 28, 8, 190, 35, 1451, 103, 6],\n",
              " [69, 177, 23, 389, 35, 118, 70],\n",
              " [58, 153, 226, 177, 360, 3, 5, 62],\n",
              " [1452, 113, 139, 1453, 39],\n",
              " [6, 5, 538, 53],\n",
              " [32, 17, 19, 1454],\n",
              " [6, 27, 729, 209, 368, 191, 23, 312],\n",
              " [648, 1455, 331],\n",
              " [730],\n",
              " [267, 203, 229, 2, 10, 448],\n",
              " [286, 636, 339],\n",
              " [432, 679, 104, 101, 1456, 36, 706],\n",
              " [7, 2, 7, 6, 119, 19, 472],\n",
              " [689, 168, 8],\n",
              " [637, 248, 42, 731, 68, 656, 1457],\n",
              " [116, 1458, 7, 340, 732, 294, 1459, 1460, 1461, 1462, 1463, 1464, 1465],\n",
              " [455, 1466, 171, 335],\n",
              " [7, 4, 1467, 148, 34],\n",
              " [127, 19, 152, 1468, 1469, 325],\n",
              " [661, 149, 9, 18, 230, 229, 2, 137],\n",
              " [237, 1470, 31, 220],\n",
              " [1471, 733, 1472, 23, 510, 21, 73],\n",
              " [1473, 17, 67, 464, 556, 627],\n",
              " [44, 247, 198, 703, 262, 306, 15],\n",
              " [1474, 457, 726, 1475, 300],\n",
              " [12, 256, 1476, 1477, 1478, 38, 454, 174, 13, 116],\n",
              " [3, 5, 201],\n",
              " [1479, 1480, 20, 1481],\n",
              " [44, 734, 735, 251, 489, 249, 328, 36, 4, 91, 101, 223, 36, 2, 370],\n",
              " [17, 13, 385, 1482, 166],\n",
              " [5, 534, 7, 2, 7, 6],\n",
              " [423, 278, 736, 87],\n",
              " [2, 5],\n",
              " [79],\n",
              " [473, 287],\n",
              " [47, 308, 62, 1483, 1484, 3, 20, 142, 39],\n",
              " [3, 165],\n",
              " [250, 12, 12, 466, 1485, 1486, 731, 492, 568, 1487, 112, 151, 1488, 3, 20],\n",
              " [389, 4, 421, 395, 396, 3, 147],\n",
              " [52, 44, 43, 1489, 474, 1490, 123, 414],\n",
              " [1491, 3, 124, 2, 257, 122],\n",
              " [1492, 195, 269],\n",
              " [699, 1493, 1494, 264, 24],\n",
              " [604, 3, 9, 1495, 1496],\n",
              " [1497, 185, 1498, 1499, 719, 271, 113, 320, 433],\n",
              " [12, 65, 150, 30, 5, 20],\n",
              " [3, 236],\n",
              " [52, 178, 153, 86],\n",
              " [227],\n",
              " [737, 52, 184, 1500, 1501, 1502],\n",
              " [308, 1503, 738, 3, 65, 63, 129, 475, 180, 2, 1504, 694, 46, 150, 35, 63, 63],\n",
              " [31, 79, 4],\n",
              " [374, 107],\n",
              " [13, 1505, 145, 1506, 6, 739, 258, 193],\n",
              " [1507, 150, 552, 52, 53, 20],\n",
              " [207, 665, 70, 283, 476, 11, 1508, 76, 1509, 44, 20],\n",
              " [32, 57, 177, 19, 281, 441, 447, 259, 151, 197, 1510, 724],\n",
              " [1511, 56, 2, 740, 1512, 1513, 7, 477, 81, 1514, 35, 34],\n",
              " [544, 213, 112, 153, 12, 5],\n",
              " [671, 1515, 211],\n",
              " [1516, 52, 52, 1517, 55],\n",
              " [61, 74, 271, 28, 45, 194],\n",
              " [1518, 580, 238],\n",
              " [154, 10, 114, 1519],\n",
              " [1520, 1521, 252, 71, 176, 3, 68, 7, 6, 251, 2, 686],\n",
              " [249, 180, 238, 3, 1522, 1523],\n",
              " [5, 581],\n",
              " [1524, 1525, 5],\n",
              " [27, 3, 165],\n",
              " [158, 159, 19, 1526],\n",
              " [470, 1527, 123, 14, 1528, 478],\n",
              " [4, 157, 741, 1529, 1530],\n",
              " [41, 30],\n",
              " [696],\n",
              " [2, 332, 13],\n",
              " [7, 2],\n",
              " [40, 46, 8, 257, 122],\n",
              " [39, 61, 459, 458, 297, 1531],\n",
              " [7, 4, 1532, 79, 74, 130],\n",
              " [107, 1533, 175, 87, 33, 1534, 174],\n",
              " [3, 42, 73, 1535, 1536],\n",
              " [429, 479, 674],\n",
              " [253, 276, 331, 45],\n",
              " [742, 440, 743, 22],\n",
              " [1537, 744, 1538, 17, 31, 271, 26],\n",
              " [3, 313, 30],\n",
              " [102, 7, 715, 1539, 1540, 558, 1541, 1542],\n",
              " [1543, 37, 353, 352, 1544, 1545, 1546, 1547, 24, 675],\n",
              " [641, 146, 745, 1548],\n",
              " [250, 177, 19, 32, 1549],\n",
              " [7],\n",
              " [1550, 94],\n",
              " [225, 189, 704, 5, 1551, 1552, 685, 315],\n",
              " [32, 159],\n",
              " [420, 427, 11, 38, 28, 129, 202, 148, 1553],\n",
              " [746, 400, 747, 1554, 4, 12, 623, 475, 167],\n",
              " [1555, 192, 1556, 1557, 688],\n",
              " [16, 10],\n",
              " [741, 40, 708],\n",
              " [71, 1558, 240, 4, 738],\n",
              " [7, 612, 613],\n",
              " [79, 6, 2],\n",
              " [77, 640, 1559],\n",
              " [85, 63, 10, 8],\n",
              " [1560, 60, 29, 15, 153],\n",
              " [7, 4, 263, 92],\n",
              " [6, 82, 3, 159],\n",
              " [319, 135, 56, 27, 1561, 135, 56],\n",
              " [32, 1562, 11, 1563],\n",
              " [212, 1564, 1565, 24],\n",
              " [5, 2, 7, 1566],\n",
              " [262, 5, 64],\n",
              " [456, 412, 748],\n",
              " [95, 255, 1567, 144, 98, 247, 47, 1568, 3, 1569, 1570],\n",
              " [406, 23, 1571, 375, 1572, 442],\n",
              " [64, 1573, 1574, 1575, 13, 218, 749, 15],\n",
              " [5, 2, 5, 6],\n",
              " [134, 24],\n",
              " [105, 40, 8, 376],\n",
              " [43, 8],\n",
              " [1576, 1577, 213, 112, 1578, 98, 103, 112, 45],\n",
              " [1579, 1580, 1581, 1582, 1583, 505, 1584, 29, 154, 173, 1585, 5],\n",
              " [76, 114, 6, 82],\n",
              " [42, 50, 4, 363, 361, 24, 371, 39],\n",
              " [1586],\n",
              " [750, 50, 18, 8],\n",
              " [1587, 2, 43, 3, 714, 167, 296, 254],\n",
              " [172, 28, 1588, 542, 1589, 3, 478],\n",
              " [72, 12, 147, 382, 64],\n",
              " [46, 146, 1590, 109, 87, 79],\n",
              " [69, 23, 159, 751, 32],\n",
              " [488, 19, 38, 341, 2],\n",
              " [747, 1591, 1592, 1593, 597, 1594, 1595, 1596, 752],\n",
              " [102, 313],\n",
              " [14, 3, 92, 543],\n",
              " [6, 209, 38, 10, 753, 9, 9],\n",
              " [1597, 12, 33, 1598, 222, 172, 106],\n",
              " [143, 1599, 1600, 81, 138, 443],\n",
              " [3, 132],\n",
              " [136, 295],\n",
              " [1601, 434, 16, 10],\n",
              " [93, 737, 58, 1602, 744, 743, 58],\n",
              " [1603,\n",
              "  323,\n",
              "  479,\n",
              "  171,\n",
              "  23,\n",
              "  176,\n",
              "  171,\n",
              "  7,\n",
              "  754,\n",
              "  292,\n",
              "  54,\n",
              "  13,\n",
              "  663,\n",
              "  664,\n",
              "  58,\n",
              "  464,\n",
              "  1604],\n",
              " [12, 23, 102],\n",
              " [1605, 1606, 608, 1607, 305],\n",
              " [20, 501, 1608],\n",
              " [61, 226, 1609, 258, 117, 46, 70, 1610, 39, 100],\n",
              " [493, 1611, 754, 376],\n",
              " [52, 1612, 535, 107, 676, 214, 347, 52, 162],\n",
              " [2, 7, 57, 1613, 420],\n",
              " [200, 1614, 1615, 336, 91, 280, 1616],\n",
              " [79, 94, 130],\n",
              " [7, 2, 79, 6],\n",
              " [20, 23, 132, 555, 1617, 461, 146, 366, 1618, 1619, 428, 66, 254, 369],\n",
              " [755, 1620, 1621, 755],\n",
              " [1622, 1623, 52, 17, 80],\n",
              " [6, 232, 5],\n",
              " [2, 261, 673, 195, 734, 249, 69, 259, 35],\n",
              " [1624, 176, 43, 20, 1625, 270, 40, 1626],\n",
              " [697, 756, 22, 29],\n",
              " [131, 9, 2, 6],\n",
              " [17, 657, 563, 1627, 246, 353, 141, 1628, 1629, 98, 631],\n",
              " [105, 18, 99, 8, 381, 92],\n",
              " [174, 219, 17, 41, 261, 1630],\n",
              " [139, 1631, 30, 80, 2, 1632, 19, 6],\n",
              " [37, 406, 756, 1633, 342, 757],\n",
              " [18, 758, 759],\n",
              " [22, 119, 175, 22, 83],\n",
              " [62, 253],\n",
              " [27, 3, 126, 260, 1634, 260, 75, 1635, 83, 1636, 4],\n",
              " [1637, 112, 147, 3, 5, 62],\n",
              " [3, 8],\n",
              " [181, 596, 6, 149, 9, 1638, 200, 670],\n",
              " [1639, 54, 1640, 684, 325, 116],\n",
              " [57, 91, 401, 54, 204, 1641, 1642, 325, 717],\n",
              " [391, 95, 1643, 210, 33, 1644, 193, 512, 1645, 1646],\n",
              " [163, 1647, 722, 374, 47, 83, 181, 1648, 162],\n",
              " [44, 188, 218, 55, 1649, 723],\n",
              " [1650, 330, 3, 1651, 360, 618, 384, 367],\n",
              " [1652, 135, 141, 107, 1653, 66, 1654, 324],\n",
              " [244, 133, 11, 69, 33, 10, 77],\n",
              " [1655, 132, 66, 188, 760, 1656, 760, 129, 761, 1657],\n",
              " [27, 161, 166, 43, 144, 168, 234],\n",
              " [63, 223, 36, 33, 292, 752, 33, 136, 1658],\n",
              " [7, 4, 34],\n",
              " [1659, 242, 642, 5],\n",
              " [6, 182, 494, 23],\n",
              " [2, 5, 6, 5, 95, 5],\n",
              " [4, 3, 119, 2, 365, 392],\n",
              " [52, 117, 474, 213, 9, 1660, 1661],\n",
              " [6, 528, 41],\n",
              " [27, 152],\n",
              " [153, 9, 592],\n",
              " [20, 231, 300, 14, 762, 10, 8],\n",
              " [1662, 24],\n",
              " [315, 439, 1663, 1664, 1665, 95, 5, 2],\n",
              " [121, 1666, 408, 709, 1667, 134, 135, 56],\n",
              " [345, 182, 68, 414, 220],\n",
              " [7, 11, 175, 204, 1668, 78],\n",
              " [2, 3, 80, 3, 50, 228, 1669, 1670, 480],\n",
              " [763, 82, 6],\n",
              " [1671, 1672, 134, 24],\n",
              " [349, 707, 62, 545, 67],\n",
              " [5, 61, 202],\n",
              " [1673, 320, 1674, 1675, 9, 702, 321, 222, 1676, 1677],\n",
              " [1678, 1679, 41],\n",
              " [299, 3, 5],\n",
              " [31, 1680, 30],\n",
              " [1681, 1682, 33, 79, 764, 1683, 1684],\n",
              " [107, 311, 1685, 130, 245, 123, 1686, 38, 1687],\n",
              " [86, 765, 5, 62, 1688, 261, 1689, 115],\n",
              " [1690, 27, 21, 729, 282, 4, 1691],\n",
              " [766, 195],\n",
              " [3, 99, 8],\n",
              " [16, 118, 1692, 50, 4, 100, 31, 45],\n",
              " [32, 177, 23, 209, 38, 767, 1693, 518, 1694, 1695, 1696, 32],\n",
              " [7, 102, 19, 251, 6],\n",
              " [426, 352, 216, 157, 115, 295],\n",
              " [2, 1697, 529],\n",
              " [1698, 1699, 121, 409, 108, 1700, 9, 28, 455, 87, 1701, 3, 1702, 5, 87],\n",
              " [1703, 1704, 416, 1705, 77],\n",
              " [1706, 1707, 1708, 683, 390, 120, 362, 211, 78],\n",
              " [5, 46, 435, 4, 202, 1709, 768, 4, 768, 1710, 1711, 196, 78],\n",
              " [172, 481, 12, 5, 481, 59],\n",
              " [4, 7],\n",
              " [192, 2],\n",
              " [33, 162, 1712, 147, 4],\n",
              " [27, 177, 1713],\n",
              " [6, 177, 19],\n",
              " [301, 96, 322, 588],\n",
              " [4, 23, 1714],\n",
              " [1715, 25],\n",
              " [438, 1716, 4, 146, 289, 160, 589, 517, 299, 67, 769, 770, 62, 770],\n",
              " [49, 34, 1717, 120, 1718],\n",
              " [3, 614, 1719, 28, 198, 474, 38, 609, 357, 522, 667, 191, 35, 2],\n",
              " [1720, 1721, 625, 13, 132, 61],\n",
              " [48, 11, 15, 28, 24, 30, 81, 179, 111, 79, 354],\n",
              " [69, 1722, 327, 47, 35, 83, 1723, 14, 3, 1724, 4],\n",
              " [6, 106, 309],\n",
              " [4, 125, 3, 1725, 632, 12, 125],\n",
              " [1726],\n",
              " [37, 4],\n",
              " [50, 467, 280],\n",
              " [2, 106],\n",
              " [1727, 1728, 59, 413, 1729, 601],\n",
              " [206, 124, 462, 462, 27, 1730, 194],\n",
              " [4, 616, 1731],\n",
              " [43, 14, 3, 34],\n",
              " [3, 235, 201],\n",
              " [37, 1732, 2, 23, 1733, 1734, 1735, 1736, 96, 757, 1737, 1738],\n",
              " [1739, 1740, 330, 347],\n",
              " [482, 6],\n",
              " [40, 15, 10],\n",
              " [2, 68, 187],\n",
              " [167, 51, 4, 14, 42, 460, 465],\n",
              " [6, 1741, 13],\n",
              " [37, 71, 156, 1742, 125, 1743, 1744],\n",
              " [503, 436, 233, 137],\n",
              " [182, 6],\n",
              " [21, 20, 110, 232, 2, 332, 97, 63],\n",
              " [13, 6, 2, 15, 1745, 69, 5, 19, 47, 120],\n",
              " [103],\n",
              " [705, 461, 3, 369, 149, 69, 106, 316],\n",
              " [114, 7, 30],\n",
              " [18, 86, 2, 1746, 293, 1747, 1748, 739, 42, 1749, 73],\n",
              " [2, 62, 125, 210, 1750, 197],\n",
              " [728, 154, 1751, 8, 109, 701, 146],\n",
              " [328, 628, 1752, 12, 254, 53, 2],\n",
              " [2, 28, 5, 579],\n",
              " [390, 202, 196, 269, 441, 256, 266, 55],\n",
              " [40, 8],\n",
              " [49, 3, 471, 321, 1753],\n",
              " [4, 450, 21, 56],\n",
              " [14, 3, 92, 4],\n",
              " [291, 27, 46, 1754, 343, 56, 79],\n",
              " [1755, 137, 1756, 60, 1757, 1758, 15, 153],\n",
              " [41, 120, 3, 1759, 1760, 145, 224, 6, 111, 316, 23, 1761, 1762, 117, 1763],\n",
              " [337, 7, 1764],\n",
              " [105, 14, 3, 10],\n",
              " [425, 107, 355, 771],\n",
              " [167, 255, 6, 7],\n",
              " [373, 1765, 87, 1766, 183, 174, 12, 3, 188, 463, 199],\n",
              " [1767, 44, 1768, 1769, 66, 267, 1770],\n",
              " [76, 152, 180, 7, 476, 1771],\n",
              " [205, 50, 84, 1772, 51, 33, 296, 4, 124, 138, 157],\n",
              " [105, 40, 99, 8],\n",
              " [60, 1773, 29],\n",
              " [4, 31, 5, 23, 96, 477, 22],\n",
              " [215, 7, 224, 6, 417, 8],\n",
              " [121,\n",
              "  117,\n",
              "  3,\n",
              "  121,\n",
              "  123,\n",
              "  117,\n",
              "  315,\n",
              "  469,\n",
              "  1774,\n",
              "  391,\n",
              "  32,\n",
              "  1775,\n",
              "  2,\n",
              "  1776,\n",
              "  742,\n",
              "  21,\n",
              "  1777,\n",
              "  1778,\n",
              "  253,\n",
              "  1779],\n",
              " [37, 108, 453],\n",
              " [57, 1780, 611],\n",
              " [1781, 635, 1782, 100, 29, 154, 1783, 1784, 1785],\n",
              " [4, 79, 65, 303, 1786, 403, 645],\n",
              " [71, 382, 4, 10],\n",
              " [6, 7, 38, 329, 28, 727, 110],\n",
              " [83, 140, 469, 1787, 1788, 417, 438, 1789, 140, 6, 82, 13],\n",
              " [772, 435, 151, 56, 27, 1790, 113, 20],\n",
              " [60, 71, 15, 34, 1791, 1792],\n",
              " [103, 22, 1793, 7, 6, 1794, 54, 340, 472],\n",
              " [468, 244, 176, 691, 646, 30],\n",
              " [1795, 477, 250],\n",
              " [1796, 115],\n",
              " [29, 53, 570, 1797, 1798],\n",
              " [10, 4, 595],\n",
              " [37, 1799, 20, 203, 1800, 447, 1801],\n",
              " [289, 773, 5, 58, 400, 24, 1802, 765],\n",
              " [156, 546, 1803, 260, 298, 1804, 481],\n",
              " [6, 106, 2, 192],\n",
              " [762, 256],\n",
              " [61, 1805, 324, 181, 153, 9, 1806, 324, 349, 1807],\n",
              " [774, 393, 1808, 207, 45, 194, 1809, 45, 774, 70, 44, 1810, 298, 115, 749],\n",
              " [151, 660, 1811, 34, 1812],\n",
              " [6, 237, 82],\n",
              " [302, 36, 63, 44, 110],\n",
              " [170, 1813, 121, 1814, 1815],\n",
              " [21, 1816, 1817, 54, 127, 134, 21, 1818, 463, 3, 1819, 1820],\n",
              " [468, 154, 1821, 52, 55, 769, 37],\n",
              " [1822, 1823, 626, 17, 1824, 4],\n",
              " [653, 142, 1825, 1826, 1827],\n",
              " [60, 229, 15],\n",
              " [436, 26, 195, 33, 116, 274],\n",
              " [65, 48, 50, 69, 7, 107, 6],\n",
              " [58, 571, 5],\n",
              " [1828, 317, 5],\n",
              " [263, 1829, 145, 1830, 1831],\n",
              " [131, 7, 30],\n",
              " [775, 201, 268],\n",
              " [457, 647, 246, 444, 736, 1832, 1833, 407, 1834],\n",
              " [84, 1835, 173, 1836],\n",
              " [275, 1837, 111],\n",
              " [91, 3, 1838],\n",
              " [17, 83, 9, 172, 1839, 3, 47, 439],\n",
              " [227, 204, 76, 268, 212],\n",
              " [172, 1840, 24],\n",
              " [40, 1841],\n",
              " [258, 1842, 26, 84, 144],\n",
              " [170, 3, 471, 746, 118, 1843, 1844, 265, 129, 9, 1845, 1846, 582],\n",
              " [301],\n",
              " [149, 410, 599, 49, 215, 506, 101, 490, 9],\n",
              " [1847, 1848, 85, 1849, 610, 64, 16, 1850],\n",
              " [27, 3, 147, 1851, 2],\n",
              " [132, 72, 767, 1852, 16, 9, 1853],\n",
              " [12, 164, 1854, 411, 30, 53],\n",
              " [44, 2, 1855, 84],\n",
              " [341, 59, 1856, 108, 1857, 1858, 303, 181, 21],\n",
              " [1859, 280, 1860, 1861, 204, 1862, 1863, 748, 1864, 284, 35],\n",
              " [750, 50, 40, 46, 8, 257, 122],\n",
              " [4, 725],\n",
              " [109, 11, 34, 198, 1865, 1866, 693, 1867],\n",
              " [1868, 480, 1869, 651],\n",
              " [721, 42, 553, 1870, 261, 478],\n",
              " [49, 261, 451, 87, 66, 759, 310, 114],\n",
              " [41, 776, 273, 527],\n",
              " [17, 128, 1871, 259, 35, 190, 207],\n",
              " [773, 1872, 150, 1873, 387, 16, 33, 1874, 776, 37, 20],\n",
              " [227, 30],\n",
              " [2, 629, 1875, 50, 3, 5],\n",
              " [65, 63, 192, 2, 1876, 106, 6, 4],\n",
              " [1877, 730, 1878],\n",
              " [40, 46, 8],\n",
              " [4, 735, 119, 2, 687, 72, 97],\n",
              " [4, 483, 480],\n",
              " [1879, 475, 1880, 283, 241, 437, 1881],\n",
              " [16, 763, 99],\n",
              " [115, 31, 331, 713, 1882, 432, 288],\n",
              " [619, 500, 31, 1883, 445, 31, 1884, 381, 34],\n",
              " [444, 482],\n",
              " [105, 3, 1885, 10, 8],\n",
              " [82, 479, 38, 1886],\n",
              " [3, 5, 1887, 1888],\n",
              " [1889, 290, 98, 86, 322, 777],\n",
              " [1890, 1891, 1892, 1893, 220, 778, 330, 1894, 21, 771],\n",
              " [142, 225, 3, 12, 141, 75, 483, 73],\n",
              " [39],\n",
              " [4, 187, 62, 125],\n",
              " [470, 401, 652, 29, 202, 232, 332, 13],\n",
              " [72, 377, 89],\n",
              " [208, 214, 17, 321, 157, 11, 1895, 3, 57, 19, 281, 54],\n",
              " [169, 3, 83, 9, 84, 472, 1896, 1897, 1898, 317, 698],\n",
              " [1899, 1900, 6],\n",
              " [108, 3, 121, 1901, 74],\n",
              " [28, 8, 123],\n",
              " [2, 28, 326, 1902],\n",
              " [228, 326, 158],\n",
              " [272, 143, 145, 3, 38, 1903, 41, 2, 758],\n",
              " [1904, 34, 14, 1905, 78, 1906, 1907, 33, 1908, 451],\n",
              " [1909, 1910, 1911, 10, 214, 1912, 541, 751, 1913],\n",
              " [311, 753, 151, 264, 16, 51, 205, 677, 224, 6, 278, 1914, 1915, 1916],\n",
              " [138, 39, 378, 1917, 327, 1918, 446],\n",
              " [1919, 402, 423, 63, 34, 1920, 326],\n",
              " [1921, 633, 31, 335, 1922, 314],\n",
              " [3, 185, 150, 499, 1923],\n",
              " [16, 9],\n",
              " [1924, 21, 10, 8],\n",
              " [695, 1925, 42, 53, 6, 58, 4, 88, 446, 1926, 426, 22],\n",
              " [16, 89, 458, 155, 4, 40, 8, 1927],\n",
              " [397, 143, 473, 215, 329, 3, 65, 215, 740, 1928, 1929, 509, 176],\n",
              " [169, 419, 42, 53],\n",
              " [299, 621, 35, 1930, 718],\n",
              " [2, 72, 5],\n",
              " [217, 532, 63, 1931, 69, 1932, 305],\n",
              " [678, 88, 1933, 1934],\n",
              " [41, 1935, 89, 175, 1936, 12, 473, 9, 4],\n",
              " [125, 124],\n",
              " [1937, 445, 761, 114],\n",
              " [206, 586, 11, 122, 692, 459, 36, 422, 81, 21, 2],\n",
              " [231, 34, 21, 1938, 14, 15, 236, 1939, 476],\n",
              " [772, 569, 345, 1940, 733, 1941, 72, 59],\n",
              " [2, 332],\n",
              " [126, 282, 766, 1942, 14, 254, 96, 142, 99, 22],\n",
              " [1943, 260, 297, 142, 1944],\n",
              " [1945, 1946, 1947, 112, 21, 1948, 386, 1949, 764, 53, 355, 322],\n",
              " [183, 1950, 307, 437, 1951, 1952, 399, 245, 123],\n",
              " [483, 73, 778, 777, 331],\n",
              " [12, 1953, 4, 1954, 1955],\n",
              " [14, 240, 4, 745, 1956],\n",
              " [1957, 453, 28, 87, 1958, 1959, 2, 86],\n",
              " [775, 201, 11, 4, 448],\n",
              " [550, 110, 88, 35, 156, 307, 452, 1960, 55],\n",
              " [732, 2, 482],\n",
              " [85, 179, 39],\n",
              " [51, 2, 73, 334, 404],\n",
              " [1961, 1962, 465],\n",
              " [131, 3, 147, 14, 3, 10, 8],\n",
              " [716, 30, 539, 51, 45, 10, 1963, 71, 88, 11],\n",
              " [1964, 1965, 75, 672, 1966, 359, 1967, 1968, 11, 128, 259, 190]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wfMTmGGp3HUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  X = pad_sequences(X,maxlen=max_len)\n",
        "  # # Pads or truncates all sequences to a fixed length of 50 tokens for uniform input to the model"
      ],
      "metadata": {
        "id": "uTH_-M68rMaP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbRY_dQdrMWj",
        "outputId": "427ee42a-d867-4f65-8a46-1faa992fd731"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ..., 333,  93,   4],\n",
              "       [  0,   0,   0, ..., 484,   3,   5],\n",
              "       [  0,   0,   0, ...,  80, 334, 335],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   3,  10,   8],\n",
              "       [  0,   0,   0, ...,  71,  88,  11],\n",
              "       [  0,   0,   0, ..., 128, 259, 190]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['sentiment'].values\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PH1P71TLrMTT",
        "outputId": "05ed4db6-681d-43ad-e52a-cfaf658adc9a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "# # Splits the data into training (80%) and testing (20%) sets for model evaluation, with reproducible results"
      ],
      "metadata": {
        "id": "o_UHRGborMQG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique,counts = np.unique(y_train,return_counts=True) # Extracts unique class labels from y_train and counts how many samples belong to each class\n",
        "dict(zip(unique,counts)) # Combines class labels and their counts into a dictionary for easy readability\n",
        "# it checks the class distribution in the training data to confirm whether the dataset is balanced or if class weighting is required"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZmmv8aZrMMu",
        "outputId": "9ac4c4d6-4d93-456d-faa1-3bcf987bff10"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{np.int64(0): np.int64(404), np.int64(1): np.int64(396)}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique,counts = np.unique(y_test,return_counts=True) # Extracts unique class labels from y_test and counts the number of samples in each class\n",
        "dict(zip(unique,counts)) # Creates a dictionary showing the distribution of sentiment classes in the test dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twgXHq_TtQYf",
        "outputId": "9f0376a9-3554-40ce-f521-f7d8856de938"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{np.int64(0): np.int64(96), np.int64(1): np.int64(104)}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Dataset | Class | Sentiment        | Count |\n",
        "| ------- | ----- | ---------------- | ----- |\n",
        "| Train   | 0     | Negative reviews | 404   |\n",
        "| Train   | 1     | Positive reviews | 396   |\n",
        "| Test    | 0     | Negative reviews | 96    |\n",
        "| Test    | 1     | Positive reviews | 104   |\n"
      ],
      "metadata": {
        "id": "pws13Yryt9GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "# Computes balanced class weights so the model gives equal importance to each sentiment class during training"
      ],
      "metadata": {
        "id": "27hXnU4Itock"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "# Converts the class weight array into a dictionary mapping class labels to their corresponding weights\n",
        "class_weights_dict\n",
        "# Displays the class-to-weight mapping used to handle class imbalance during model training\n",
        "# Class weights were computed and applied to ensure the model learns equally from all sentiment classes, reducing bias and improving classification fairness"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcF5k-Rlt33o",
        "outputId": "132a5430-4397-4994-d371-ec4981e90a34"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: np.float64(0.9900990099009901), 1: np.float64(1.0101010101010102)}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Class | Sentiment        | Class Weight | Meaning                                    |\n",
        "| ----- | ---------------- | ------------ | ------------------------------------------ |\n",
        "| 0     | Negative reviews | ~0.99        | Slightly **more samples**, so less weight  |\n",
        "| 1     | Positive reviews | ~1.01        | Slightly **fewer samples**, so more weight |\n"
      ],
      "metadata": {
        "id": "QctOxkEdvbUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(max_len,)) # Defines the model input as a padded sequence of word indices with fixed length max_len\n",
        "embedding = Embedding(input_dim=vocab_size,output_dim=64)(input_layer) # Converts word indices into 64-dimensional dense vector representations\n",
        "attention = MultiHeadAttention(num_heads=2,key_dim=64)(embedding,embedding) # Applies multi-head self-attention so each word can attend to all other words in the review\n",
        "pooling = GlobalAveragePooling1D()(attention)# Aggregates token-level attention outputs into a single sentence-level representation\n",
        "output = Dense(1,activation='sigmoid')(pooling) # Produces a probability score for binary sentiment classification (positive or negative)\n",
        "\n",
        "# Input â†’ Embedding â†’ Multi-Head Self Attention â†’ Global Avg Pool â†’ Sigmoid Output"
      ],
      "metadata": {
        "id": "MQcyEvG1t30l"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=input_layer,outputs=output) # Creates the final Keras model by connecting the input layer to the output layer\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "# The attention-based sentiment model was compiled using the Adam optimizer and binary cross-entropy loss to efficiently learn from binary-labeled review data\n",
        "# Adam provides fast and stable convergence for deep NLP models, and binary cross-entropy is the standard loss function for sigmoid-based binary classification tasks."
      ],
      "metadata": {
        "id": "OMHdCW9Gt3xp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "tx9Ilg8pt3vC",
        "outputId": "ddebb496-e078-4fd3-e521-fe3e52535399"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚    \u001b[38;5;34m320,000\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚     \u001b[38;5;34m33,216\u001b[0m â”‚ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m65\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,216</span> â”‚ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m353,281\u001b[0m (1.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353,281</span> (1.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m353,281\u001b[0m (1.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353,281</span> (1.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=20,batch_size=32,validation_data=(X_test, y_test),class_weight=class_weights_dict)\n",
        "# Multiple epochs allow the model to progressively refine its weights.\n",
        "# batch size-Number of samples processed per gradient update , provides stable learning and efficient GPU/CPU utilization\n",
        "# Validation helps monitor generalization and detect overfitting early\n",
        "# applied class weights during training and monitored validation performance to ensure balanced learning and good generalization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWrr35vht3rj",
        "outputId": "a43f99d0-83ca-4ce0-bfbc-ec39b942dbf6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.4955 - loss: 0.6939 - val_accuracy: 0.4800 - val_loss: 0.6933\n",
            "Epoch 2/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5121 - loss: 0.6932 - val_accuracy: 0.5200 - val_loss: 0.6916\n",
            "Epoch 3/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5748 - loss: 0.6910 - val_accuracy: 0.5200 - val_loss: 0.6942\n",
            "Epoch 4/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5346 - loss: 0.6847 - val_accuracy: 0.4800 - val_loss: 0.6896\n",
            "Epoch 5/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5875 - loss: 0.6796 - val_accuracy: 0.5000 - val_loss: 0.6663\n",
            "Epoch 6/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7372 - loss: 0.5335 - val_accuracy: 0.7400 - val_loss: 0.6286\n",
            "Epoch 7/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9114 - loss: 0.2528 - val_accuracy: 0.8100 - val_loss: 0.6456\n",
            "Epoch 8/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9730 - loss: 0.0774 - val_accuracy: 0.8050 - val_loss: 0.5998\n",
            "Epoch 9/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9881 - loss: 0.0345 - val_accuracy: 0.8100 - val_loss: 0.7747\n",
            "Epoch 10/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9952 - loss: 0.0171 - val_accuracy: 0.7800 - val_loss: 0.8215\n",
            "Epoch 11/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9995 - loss: 0.0104 - val_accuracy: 0.7800 - val_loss: 0.9107\n",
            "Epoch 12/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9998 - loss: 0.0045 - val_accuracy: 0.7750 - val_loss: 0.9964\n",
            "Epoch 13/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9985 - loss: 0.0034 - val_accuracy: 0.7750 - val_loss: 1.0684\n",
            "Epoch 14/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9991 - loss: 0.0045 - val_accuracy: 0.7700 - val_loss: 1.1094\n",
            "Epoch 15/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.7750 - val_loss: 1.1689\n",
            "Epoch 16/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9948 - loss: 0.0088 - val_accuracy: 0.7850 - val_loss: 1.2244\n",
            "Epoch 17/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9979 - loss: 0.0028 - val_accuracy: 0.7800 - val_loss: 1.2578\n",
            "Epoch 18/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7700 - val_loss: 1.3175\n",
            "Epoch 19/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.7167e-04 - val_accuracy: 0.7700 - val_loss: 1.3641\n",
            "Epoch 20/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.9303e-04 - val_accuracy: 0.7700 - val_loss: 1.4037\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eda60329010>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing Phase**"
      ],
      "metadata": {
        "id": "Nghgeeklx66h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "    \"The food was amazing and the staff was very friendly\",\n",
        "    \"Worst experience ever, totally disappointed\",\n",
        "    \"I really loved the ambience and the service\",\n",
        "    \"The waiter was rude and the food was cold\",\n",
        "    \"This restaurant is absolutely fantastic\",\n",
        "    \"Not worth the money, very poor quality\",\n",
        "    \"The taste was good but the service was slow\",\n",
        "    \"I will definitely come back again\",\n",
        "    \"One of the best dining experiences I have had\"\n",
        "]"
      ],
      "metadata": {
        "id": "KN7KR9OAt3oN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- TESTING -------------------------------\n",
        "test_sentences = [\n",
        "    \"The food was amazing and the staff was very friendly\",\n",
        "    \"Worst experience ever, totally disappointed\",\n",
        "    \"I really loved the ambience and the service\",\n",
        "    \"The waiter was rude and the food was cold\",\n",
        "    \"This restaurant is absolutely fantastic\",\n",
        "    \"Not worth the money, very poor quality\",\n",
        "    \"The taste was good but the service was slow\",\n",
        "    \"I will definitely come back again\",\n",
        "    \"One of the best dining experiences I have had\"\n",
        "]\n",
        "\n",
        "# Run predictions on each test sentence\n",
        "for review in test_sentences:                         # Loop through each review sentence\n",
        "\n",
        "    cleaned = preprocess_text(review)                  # Clean the review (lowercase, remove symbols, stopwords)\n",
        "\n",
        "    seq = tokenizer.texts_to_sequences([cleaned])      # Convert cleaned text into numbers (tokens)\n",
        "\n",
        "    pad = pad_sequences(seq, maxlen=max_len)           # Make sequence length fixed by padding\n",
        "\n",
        "    pred = model.predict(pad)[0][0]                    # Get prediction probability from the model-ðŸ”¹ model here is the SAME model that was trained using model.fit()\n",
        "\n",
        "    print(f\"Review: {review}\")                          # Print original review\n",
        "    print(f\"Cleaned: {cleaned}\")                        # Print cleaned review\n",
        "\n",
        "    # If probability > 0.5 â†’ Positive, else Negative\n",
        "    print(f\"Predicted Sentiment: {'Positive ðŸ˜€' if pred > 0.5 else 'Negative ðŸ˜ž'}\")\n",
        "\n",
        "    print(\"-\" * 60)                                     # Print separator line\n",
        "\n",
        "#ðŸ”¹ model here is the SAME model that was trained using model.fit()\n",
        "#ðŸ”¹ model.fit() modifies the weights inside model\n",
        "#ðŸ”¹ model.predict() uses those learned weights\n",
        "#ðŸ‘‰ Same variable name = same trained object\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WzI6y_Hx5uQ",
        "outputId": "a4756e6c-79f5-4937-a4ef-954b3af3f9be"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
            "Review: The food was amazing and the staff was very friendly\n",
            "Cleaned: food amazing staff friendly\n",
            "Predicted Sentiment: Positive ðŸ˜€\n",
            "------------------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Review: Worst experience ever, totally disappointed\n",
            "Cleaned: worst experience ever totally disappointed\n",
            "Predicted Sentiment: Negative ðŸ˜ž\n",
            "------------------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Review: I really loved the ambience and the service\n",
            "Cleaned: really loved ambience service\n",
            "Predicted Sentiment: Positive ðŸ˜€\n",
            "------------------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Review: The waiter was rude and the food was cold\n",
            "Cleaned: waiter rude food cold\n",
            "Predicted Sentiment: Negative ðŸ˜ž\n",
            "------------------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Review: This restaurant is absolutely fantastic\n",
            "Cleaned: restaurant absolutely fantastic\n",
            "Predicted Sentiment: Positive ðŸ˜€\n",
            "------------------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Review: Not worth the money, very poor quality\n",
            "Cleaned: not worth money poor quality\n",
            "Predicted Sentiment: Negative ðŸ˜ž\n",
            "------------------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Review: The taste was good but the service was slow\n",
            "Cleaned: taste good service slow\n",
            "Predicted Sentiment: Negative ðŸ˜ž\n",
            "------------------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Review: I will definitely come back again\n",
            "Cleaned: definitely come back\n",
            "Predicted Sentiment: Positive ðŸ˜€\n",
            "------------------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Review: One of the best dining experiences I have had\n",
            "Cleaned: one best dining experiences\n",
            "Predicted Sentiment: Positive ðŸ˜€\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conclusion**\n",
        "\n",
        "The trained attention-based sentiment model was used to predict sentiment on unseen real-world reviews by applying the same preprocessing, tokenization, padding, and probability thresholding pipeline.\n",
        "\n",
        "So this model can be tested on new data , by passing unseen sentences through the same preprocessing and tokenization pipeline used during training, padded them to a fixed length, and used the trained model to generate probability-based sentiment predictions.\n",
        "\n",
        "In this project, we developed a sentiment analysis system that automatically classifies customer reviews as positive or negative using Natural Language Processing (NLP) techniques. The text data was first cleaned, tokenized, and converted into numerical form using word embeddings, enabling the model to process human language effectively.\n",
        "\n",
        "The model uses a Transformer-based self-attention mechanism, which allows it to understand the context of words by analyzing their relationships within a sentence. This helps the system focus on important sentiment-related keywords rather than processing text sequentially, improving overall accuracy compared to traditional models.\n",
        "\n",
        "After training and validation, the model showed reliable performance on unseen test data, indicating good generalization capability. The results confirm that the attention-based model can effectively capture semantic meaning and sentiment patterns in real-world customer reviews.\n",
        "\n",
        "Overall, this project demonstrates a practical application of deep learning, self-attention, and NLP pipelines for automated text classification."
      ],
      "metadata": {
        "id": "D4uxxPNY0ih5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D_NpWYlq4dYp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}